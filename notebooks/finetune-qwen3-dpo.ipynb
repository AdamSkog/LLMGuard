{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41f749ce",
   "metadata": {},
   "source": [
    "# DPO Fine-tuning Qwen3 8B for Code Vulnerability Detection with Unsloth\n",
    "\n",
    "This notebook implements DPO fine-tuning for Qwen3 8B (or 4B) on the `CyberNative/Code_Vulnerability_Security_DPO` dataset using Unsloth for 2-5x speedup.\n",
    "The goal is to align the model with preferences for secure code generation.\n",
    "\n",
    "**Key improvements:**\n",
    "- Uses Qwen3 4B\n",
    "- Leverages Unsloth for significant training speedup\n",
    "- Optimized for T4 GPU x 2 setup (Kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2d3584",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T23:02:48.093879Z",
     "iopub.status.busy": "2025-05-26T23:02:48.093709Z",
     "iopub.status.idle": "2025-05-26T23:06:15.397198Z",
     "shell.execute_reply": "2025-05-26T23:06:15.396257Z",
     "shell.execute_reply.started": "2025-05-26T23:02:48.093861Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install required packages with Unsloth\n",
    "# !pip install -q \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "!pip install unsloth\n",
    "!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git\n",
    "!pip install -q transformers datasets accelerate bitsandbytes peft trl sentencepiece evaluate\n",
    "\n",
    "print(\"Installation complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9f7b7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T23:08:16.238064Z",
     "iopub.status.busy": "2025-05-26T23:08:16.237458Z",
     "iopub.status.idle": "2025-05-26T23:08:16.412338Z",
     "shell.execute_reply": "2025-05-26T23:08:16.411643Z",
     "shell.execute_reply.started": "2025-05-26T23:08:16.238040Z"
    }
   },
   "outputs": [],
   "source": [
    "# WandB Authentication and Setup\n",
    "import wandb\n",
    "import os\n",
    "\n",
    "# Get WandB API key from Kaggle secrets\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    user_secrets = UserSecretsClient()\n",
    "    wandb_api_key = user_secrets.get_secret(\"WANDB_API_KEY\")\n",
    "    os.environ[\"WANDB_API_KEY\"] = wandb_api_key\n",
    "    print(\"✅ WandB API key loaded from Kaggle secrets\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Could not load WandB API key from secrets: {e}\")\n",
    "    print(\"Please add your WandB API key to Kaggle secrets with key name 'WANDB_API_KEY'\")\n",
    "\n",
    "# Login to WandB\n",
    "try:\n",
    "    wandb.login(key=wandb_api_key)\n",
    "    print(\"Successfully logged in to WandB\")\n",
    "    \n",
    "    # Get the actual username after login\n",
    "    wandb_user = wandb.api.default_entity\n",
    "    print(f\"WandB username: {wandb_user}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"WandB login failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba30273c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T23:11:18.479660Z",
     "iopub.status.busy": "2025-05-26T23:11:18.479130Z",
     "iopub.status.idle": "2025-05-26T23:11:51.504489Z",
     "shell.execute_reply": "2025-05-26T23:11:51.503632Z",
     "shell.execute_reply.started": "2025-05-26T23:11:18.479636Z"
    }
   },
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel, is_bfloat16_supported, PatchDPOTrainer\n",
    "import torch\n",
    "\n",
    "# Patch DPO Trainer for Unsloth compatibility\n",
    "PatchDPOTrainer()\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import TrainingArguments\n",
    "from trl import DPOTrainer, DPOConfig\n",
    "\n",
    "# Help avoid memory fragmentation!!!\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"Device name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "print(\"✅ All imports successful with Unsloth optimizations enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa32ec3-b64d-449c-bdc1-b325ae923d13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T23:11:54.542096Z",
     "iopub.status.busy": "2025-05-26T23:11:54.541279Z",
     "iopub.status.idle": "2025-05-26T23:11:54.548423Z",
     "shell.execute_reply": "2025-05-26T23:11:54.547711Z",
     "shell.execute_reply.started": "2025-05-26T23:11:54.542068Z"
    }
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "    reserved = torch.cuda.memory_reserved() / 1024**3\n",
    "    total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f\"GPU Memory:\")\n",
    "    print(f\"   Total: {total:.2f} GB\")\n",
    "    print(f\"   Allocated: {allocated:.2f} GB\") \n",
    "    print(f\"   Reserved: {reserved:.2f} GB\")\n",
    "    print(f\"   Free: {total - reserved:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8448c969",
   "metadata": {},
   "source": [
    "## 1. Data Acquisition and Preparation\n",
    "\n",
    "We will load the `CyberNative/Code_Vulnerability_Security_DPO` dataset and prepare it for DPO training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238bd41d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T23:12:01.424871Z",
     "iopub.status.busy": "2025-05-26T23:12:01.424160Z",
     "iopub.status.idle": "2025-05-26T23:12:03.604091Z",
     "shell.execute_reply": "2025-05-26T23:12:03.603203Z",
     "shell.execute_reply.started": "2025-05-26T23:12:01.424845Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = \"CyberNative/Code_Vulnerability_Security_DPO\"\n",
    "\n",
    "# Load dataset\n",
    "print(f\"Loading dataset: {dataset_name}\")\n",
    "dataset = load_dataset(dataset_name)\n",
    "print(\"Dataset loaded.\")\n",
    "\n",
    "# Rename 'question' to 'prompt' if needed\n",
    "if 'question' in dataset['train'].column_names:\n",
    "    dataset = dataset.rename_column(\"question\", \"prompt\")\n",
    "    print(\"Renamed 'question' column to 'prompt'.\")\n",
    "\n",
    "# Split into training and evaluation sets (if not already split)\n",
    "if 'test' not in dataset:\n",
    "    print(\"Splitting dataset into train and test (90/10)...\")\n",
    "    dataset = dataset['train'].train_test_split(test_size=0.1, seed=42)\n",
    "    print(\"Dataset split into train and test sets.\")\n",
    "\n",
    "print(\"Dataset sizes:\")\n",
    "for split_name, split_data in dataset.items():\n",
    "    print(f\"- {split_name}: {len(split_data)}\")\n",
    "\n",
    "print(\"\\nSample datapoint:\")\n",
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298d08b9",
   "metadata": {},
   "source": [
    "## 2. Model Selection and Loading with Unsloth\n",
    "\n",
    "We'll use Qwen3 8B with Unsloth optimizations. If memory is insufficient, we'll fall back to Qwen3 4B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab780ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T23:12:06.139201Z",
     "iopub.status.busy": "2025-05-26T23:12:06.138880Z",
     "iopub.status.idle": "2025-05-26T23:12:32.496708Z",
     "shell.execute_reply": "2025-05-26T23:12:32.495912Z",
     "shell.execute_reply.started": "2025-05-26T23:12:06.139176Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "max_seq_length = 2048  # Qwen3 supports longer contexts\n",
    "dtype = None  # Auto-detect (bfloat16 for modern GPUs, float16 for older)\n",
    "load_in_4bit = True  # Use 4-bit quantization for memory efficiency\n",
    "\n",
    "# Try 8B first, fall back to 4B if needed\n",
    "model_options = [\n",
    "    # \"unsloth/Qwen3-8B-unsloth-bnb-4bit\",  # 8B model\n",
    "    \"unsloth/Qwen3-4B-unsloth-bnb-4bit\",  # 4B fallback\n",
    "]\n",
    "\n",
    "model = None\n",
    "tokenizer = None\n",
    "selected_model = None\n",
    "\n",
    "for model_name in model_options:\n",
    "    try:\n",
    "        print(f\"Attempting to load: {model_name}\")\n",
    "        model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "            model_name=model_name,\n",
    "            max_seq_length=max_seq_length,\n",
    "            dtype=dtype,\n",
    "            load_in_4bit=load_in_4bit,\n",
    "            # token=\"hf_...\",  # Use if needed for gated models\n",
    "        )\n",
    "        selected_model = model_name\n",
    "        print(f\"✅ Successfully loaded: {model_name}\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to load {model_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "if model is None:\n",
    "    raise RuntimeError(\"Failed to load any model. Please check your setup.\")\n",
    "\n",
    "print(f\"\\nUsing model: {selected_model}\")\n",
    "print(f\"Max sequence length: {max_seq_length}\")\n",
    "print(f\"Data type: {dtype or 'auto-detected'}\")\n",
    "print(f\"4-bit quantization: {load_in_4bit}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d61249",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T23:12:37.737296Z",
     "iopub.status.busy": "2025-05-26T23:12:37.736977Z",
     "iopub.status.idle": "2025-05-26T23:12:45.986096Z",
     "shell.execute_reply": "2025-05-26T23:12:45.985270Z",
     "shell.execute_reply.started": "2025-05-26T23:12:37.737274Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add LoRA adapters with Unsloth optimizations\n",
    "print(\"Adding LoRA adapters with Unsloth optimizations...\")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=32,  # LoRA rank - higher for better performance\n",
    "    target_modules=[\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",  # Include MLP layers for Qwen3\n",
    "    ],\n",
    "    lora_alpha=32,  # LoRA scaling factor\n",
    "    lora_dropout=0,  # Unsloth optimized for 0 dropout\n",
    "    bias=\"none\",  # Unsloth optimized for no bias\n",
    "    use_gradient_checkpointing=\"unsloth\",  # Unsloth's optimized checkpointing\n",
    "    random_state=3407,\n",
    "    use_rslora=False,  # Rank stabilized LoRA\n",
    "    loftq_config=None,  # LoftQ config\n",
    ")\n",
    "\n",
    "print(\"LoRA adapters added successfully\")\n",
    "print(f\"LoRA rank: 32\")\n",
    "print(f\"Target modules: {len(['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj'])} modules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46cce34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "output_dir = \"./dpo_qwen3_security_finetuned\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# CRITICAL: Much more conservative sequence lengths for DPO\n",
    "max_prompt_length = 256  # REDUCED from 512 - DPO needs shorter prompts\n",
    "max_length = 1024  # REDUCED from 1792 - DPO is memory intensive\n",
    "\n",
    "# Training hyperparameters optimized for T4 + DPO\n",
    "num_train_epochs = 3\n",
    "per_device_train_batch_size = 1  # Keep at 1 for DPO\n",
    "gradient_accumulation_steps = 4  # REDUCED from 8 for memory\n",
    "learning_rate = 5e-6  # Lower LR for DPO stability\n",
    "beta = 0.1  # DPO beta parameter\n",
    "\n",
    "# Initialize WandB run with proper error handling\n",
    "try:\n",
    "    # Get the current WandB user (if logged in)\n",
    "    try:\n",
    "        wandb_entity = wandb.api.default_entity\n",
    "    except:\n",
    "        wandb_entity = None  # Let WandB use default\n",
    "    \n",
    "    wandb.init(\n",
    "        project=\"llm-guard-qwen3-dpo-training\",\n",
    "        entity=wandb_entity,  # Use detected entity or None for default\n",
    "        name=f\"qwen3-{selected_model.split('/')[-1]}-security-dpo-v2-conservative\",\n",
    "        config={\n",
    "            \"model_name\": selected_model,\n",
    "            \"dataset\": \"CyberNative/Code_Vulnerability_Security_DPO\",\n",
    "            \"method\": \"DPO\",\n",
    "            \"framework\": \"Unsloth\",\n",
    "            \"quantization\": \"4-bit\",\n",
    "            \"lora_rank\": 32,\n",
    "            \"lora_alpha\": 32,\n",
    "            \"batch_size\": per_device_train_batch_size,\n",
    "            \"gradient_accumulation_steps\": gradient_accumulation_steps,\n",
    "            \"effective_batch_size\": per_device_train_batch_size * gradient_accumulation_steps,\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"num_epochs\": num_train_epochs,\n",
    "            \"max_prompt_length\": max_prompt_length,\n",
    "            \"max_length\": max_length,\n",
    "            \"beta\": beta,\n",
    "            \"gpu\": \"T4\",\n",
    "            \"platform\": \"Kaggle\",\n",
    "            \"memory_optimization\": \"conservative\"\n",
    "        },\n",
    "        tags=[\"dpo\", \"qwen3\", \"security\", \"code-vulnerability\", \"unsloth\", \"conservative\"]\n",
    "    )\n",
    "    \n",
    "    print(f\"WandB run initialized: {wandb.run.name}\")\n",
    "    print(f\"Dashboard URL: {wandb.run.url}\")\n",
    "    wandb_enabled = True\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"WandB initialization failed: {e}\")\n",
    "    print(\"Continuing without WandB logging...\")\n",
    "    wandb_enabled = False\n",
    "    \n",
    "    # Set environment variable to disable WandB for training\n",
    "    os.environ[\"WANDB_MODE\"] = \"disabled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c44ff3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T23:13:41.085919Z",
     "iopub.status.busy": "2025-05-26T23:13:41.085030Z",
     "iopub.status.idle": "2025-05-26T23:13:47.447639Z",
     "shell.execute_reply": "2025-05-26T23:13:47.446795Z",
     "shell.execute_reply.started": "2025-05-26T23:13:41.085885Z"
    }
   },
   "outputs": [],
   "source": [
    "# DPO Training configuration with ULTRA-CONSERVATIVE memory settings\n",
    "print(\"Initializing DPO Trainer with ultra-conservative memory settings...\")\n",
    "\n",
    "# Use DPOConfig for newer TRL versions\n",
    "training_args = DPOConfig(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    per_device_eval_batch_size=1,  # Keep at 1\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    \n",
    "    # CRITICAL: DISABLE EVALUATION to prevent memory spikes\n",
    "    eval_strategy=\"no\",  # CHANGED from \"steps\" - no evaluation during training\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=50,       # INCREASED to reduce overhead\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,     # Keep only 1 checkpoint\n",
    "    \n",
    "    # PRECISION & OPTIMIZATION\n",
    "    bf16=is_bfloat16_supported(),\n",
    "    fp16=not is_bfloat16_supported(),\n",
    "    gradient_checkpointing=True,  # Essential for memory\n",
    "    gradient_checkpointing_kwargs = {\"use_reentrant\": False},  # More memory efficient\n",
    "    \n",
    "    # AGGRESSIVE MEMORY OPTIMIZATIONS\n",
    "    remove_unused_columns=False,\n",
    "    report_to=\"wandb\" if wandb_enabled else \"none\",\n",
    "    dataloader_num_workers=0,     # No multiprocessing\n",
    "    dataloader_pin_memory=False,  # Reduce memory pressure\n",
    "    dataloader_persistent_workers=False,  # ADDED\n",
    "    \n",
    "    # OPTIMIZER SETTINGS\n",
    "    warmup_ratio=0.03,      # REDUCED warmup\n",
    "    optim=\"adamw_8bit\",     # 8-bit optimizer\n",
    "    weight_decay=0.0,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    seed=42,\n",
    "    \n",
    "    # DPO-specific parameters - CONSERVATIVE\n",
    "    beta=beta,\n",
    "    max_prompt_length=max_prompt_length,\n",
    "    max_length=max_length,\n",
    "    loss_type=\"sigmoid\",\n",
    "    \n",
    "    # ADDITIONAL MEMORY OPTIMIZATIONS\n",
    "    prediction_loss_only=True,           # Reduce memory for metrics\n",
    "    include_inputs_for_metrics=False,    # Save memory\n",
    "    disable_tqdm=False,                  # Keep progress bars\n",
    "    \n",
    "    # FORCE SMALLER BATCHES\n",
    "    max_steps=-1,  # Use epochs instead of steps\n",
    "    \n",
    "    # MEMORY CLEANUP\n",
    "    save_safetensors=True,\n",
    "    load_best_model_at_end=False,  # ADDED - don't load best model\n",
    ")\n",
    "\n",
    "print(f\"Conservative settings applied:\")\n",
    "print(f\"   • Max length: {max_length} (reduced from 1792)\")\n",
    "print(f\"   • Max prompt length: {max_prompt_length} (reduced from 512)\")\n",
    "print(f\"   • Effective batch size: {per_device_train_batch_size * gradient_accumulation_steps}\")\n",
    "print(f\"   • Evaluation: DISABLED (prevents memory spikes)\")\n",
    "print(f\"   • Expected memory usage: ~8-10GB peak\")\n",
    "\n",
    "# Initialize DPO Trainer\n",
    "dpo_trainer = DPOTrainer(\n",
    "    model=model,\n",
    "    ref_model=None,  # Unsloth handles reference model internally\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=None,  # DISABLED evaluation dataset\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "print(\"DPO Trainer initialized with ultra-conservative memory settings!\")\n",
    "print(f\"Ready for memory-efficient training on T4 GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e894e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory monitoring before training\n",
    "def print_memory_stats(stage=\"\"):\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "        reserved = torch.cuda.memory_reserved() / 1024**3\n",
    "        total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "        free = total - reserved\n",
    "        \n",
    "        print(f\"GPU Memory {stage}:\")\n",
    "        print(f\"   Total: {total:.2f} GB\")\n",
    "        print(f\"   Allocated: {allocated:.2f} GB\") \n",
    "        print(f\"   Reserved: {reserved:.2f} GB\")\n",
    "        print(f\"   Free: {free:.2f} GB\")\n",
    "        \n",
    "        if free < 4.0:\n",
    "            print(\"CRITICAL: Very low memory!\")\n",
    "        elif free < 6.0:\n",
    "            print(\"WARNING: Low memory\")\n",
    "        else:\n",
    "            print(\"GOOD: Sufficient memory\")\n",
    "        \n",
    "        return free\n",
    "    return 0\n",
    "\n",
    "# Check memory before training\n",
    "free_memory = print_memory_stats(\"before training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1e620c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T23:14:00.054959Z",
     "iopub.status.busy": "2025-05-26T23:14:00.054351Z",
     "iopub.status.idle": "2025-05-26T23:14:14.779733Z",
     "shell.execute_reply": "2025-05-26T23:14:14.778663Z",
     "shell.execute_reply.started": "2025-05-26T23:14:00.054933Z"
    }
   },
   "outputs": [],
   "source": [
    "# DPO Training configuration with Unsloth optimizations\n",
    "print(\"Initializing DPO Trainer with Unsloth optimizations...\")\n",
    "\n",
    "# Use DPOConfig for newer TRL versions\n",
    "training_args = DPOConfig(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    per_device_eval_batch_size=1,  # REDUCED for eval memory\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    \n",
    "    # MEMORY CRITICAL SETTINGS\n",
    "    eval_strategy=\"steps\",  # CHANGED from \"epoch\" to reduce memory spikes\n",
    "    eval_steps=200,         # ADDED - less frequent evaluation\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=25,       # INCREASED from 10 to reduce overhead\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,     # REDUCED from 2 to 1 (save memory)\n",
    "    \n",
    "    # PRECISION & OPTIMIZATION\n",
    "    bf16=is_bfloat16_supported(),\n",
    "    fp16=not is_bfloat16_supported(),\n",
    "    gradient_checkpointing=True,  # ADDED - crucial for memory\n",
    "    gradient_checkpointing_kwargs = {\"use_reentrant\": False},  # More memory efficient\n",
    "    \n",
    "    # MEMORY OPTIMIZATIONS\n",
    "    remove_unused_columns=False,\n",
    "    report_to=\"wandb\",  # Conditional WandB\n",
    "    dataloader_num_workers=0,     # REDUCED from 2 to 0 (prevents memory leaks)\n",
    "    dataloader_pin_memory=False,  # ADDED - reduce memory pressure\n",
    "    \n",
    "    # OPTIMIZER SETTINGS\n",
    "    warmup_ratio=0.05,      # REDUCED from 0.1 (fewer warmup steps)\n",
    "    optim=\"adamw_8bit\",\n",
    "    weight_decay=0.0,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    seed=42,\n",
    "    \n",
    "    # DPO-specific parameters\n",
    "    beta=beta,\n",
    "    max_prompt_length=max_prompt_length,\n",
    "    max_length=max_length,\n",
    "    loss_type=\"sigmoid\",\n",
    "    \n",
    "    # ADDITIONAL MEMORY OPTIMIZATIONS\n",
    "    prediction_loss_only=True,           # ADDED - reduce memory for metrics\n",
    "    include_inputs_for_metrics=False,    # ADDED - save memory\n",
    "    disable_tqdm=False,                  # Keep progress bars for monitoring\n",
    ")\n",
    "\n",
    "# Initialize DPO Trainer\n",
    "dpo_trainer = DPOTrainer(\n",
    "    model=model,\n",
    "    ref_model=None,  # Unsloth handles reference model internally\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "print(\"DPO Trainer initialized successfully with Unsloth optimizations!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cb711d",
   "metadata": {},
   "source": [
    "## 4. Training with Unsloth Acceleration\n",
    "\n",
    "Start the DPO fine-tuning process with Unsloth's optimizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0909ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T23:14:17.068145Z",
     "iopub.status.busy": "2025-05-26T23:14:17.067203Z",
     "iopub.status.idle": "2025-05-26T23:26:52.202529Z",
     "shell.execute_reply": "2025-05-26T23:26:52.201201Z",
     "shell.execute_reply.started": "2025-05-26T23:14:17.068111Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show memory stats before training\n",
    "if torch.cuda.is_available():\n",
    "    gpu_stats = torch.cuda.get_device_properties(0)\n",
    "    start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "    max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "    print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "    print(f\"{start_gpu_memory} GB of memory reserved before training.\")\n",
    "\n",
    "print(\"\\nStarting DPO training with Unsloth acceleration...\")\n",
    "print(f\"Training on {len(dataset['train'])} samples\")\n",
    "print(f\"Evaluating on {len(dataset['test'])} samples\")\n",
    "\n",
    "# Start training\n",
    "training_results = dpo_trainer.train()\n",
    "\n",
    "print(\"\\nTraining completed!\")\n",
    "print(\"\\nTraining metrics:\")\n",
    "print(training_results.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "142b212a-9d1d-4ce0-b3ed-8847e7b8d93c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T04:20:54.764545Z",
     "iopub.status.busy": "2025-05-26T04:20:54.763896Z",
     "iopub.status.idle": "2025-05-26T04:20:54.768905Z",
     "shell.execute_reply": "2025-05-26T04:20:54.768328Z",
     "shell.execute_reply.started": "2025-05-26T04:20:54.764523Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# CRITICAL: Set before any CUDA operations\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# Also try these additional settings\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True,roundup_power2_divisions:16\"\n",
    "\n",
    "# Clear and restart\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d913c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T04:21:04.316302Z",
     "iopub.status.busy": "2025-05-26T04:21:04.315816Z",
     "iopub.status.idle": "2025-05-26T04:21:04.345267Z",
     "shell.execute_reply": "2025-05-26T04:21:04.344240Z",
     "shell.execute_reply.started": "2025-05-26T04:21:04.316281Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show final memory and time stats\n",
    "if torch.cuda.is_available():\n",
    "    used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "    used_memory_for_training = round(used_memory - start_gpu_memory, 3)\n",
    "    used_percentage = round(used_memory / max_memory * 100, 3)\n",
    "    training_percentage = round(used_memory_for_training / max_memory * 100, 3)\n",
    "    \n",
    "    print(f\"{training_results.metrics['train_runtime']} seconds used for training.\")\n",
    "    print(f\"{round(training_results.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
    "    print(f\" Peak reserved memory = {used_memory} GB.\")\n",
    "    print(f\" Peak reserved memory for training = {used_memory_for_training} GB.\")\n",
    "    print(f\" Peak reserved memory % of max memory = {used_percentage}%.\")\n",
    "    print(f\" Peak reserved memory for training % of max memory = {training_percentage}%.\")\n",
    "    \n",
    "    # Log to WandB\n",
    "    wandb.log({\n",
    "        \"final_memory_usage_gb\": used_memory,\n",
    "        \"training_memory_usage_gb\": used_memory_for_training,\n",
    "        \"memory_usage_percentage\": used_percentage,\n",
    "        \"training_time_minutes\": round(training_results.metrics['train_runtime']/60, 2)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ecf4f0",
   "metadata": {},
   "source": [
    "## 5. Model Saving with Unsloth\n",
    "\n",
    "Save the trained model using Unsloth's optimized saving methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465cc5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model using Unsloth's methods\n",
    "final_model_path = os.path.join(output_dir, \"final_checkpoint\")\n",
    "print(f\"Saving model to: {final_model_path}\")\n",
    "\n",
    "# Save LoRA adapters\n",
    "model.save_pretrained(final_model_path)\n",
    "tokenizer.save_pretrained(final_model_path)\n",
    "print(\"LoRA adapters and tokenizer saved\")\n",
    "\n",
    "print(f\"\\n Model training and saving completed!\")\n",
    "print(f\" Main model location: {final_model_path}\")\n",
    "print(f\" WandB dashboard: {wandb.run.url}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
